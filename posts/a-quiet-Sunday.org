
#+TITLE: A Quiet Sunday with Emacspeak  
#+SUBTITLE: Accessibility Experiments Across Windows, WSL, and Raspberry Pi  
#+DATE: 2025-09-14  
#+FILETAGS: :Emacs:Raspberry_Pi:

*** Introduction  
When the Windows Subsystem for Linux first came online, I installed it immediately. Using a native Windows screen reader on a Linux system is not ideal. Installing a Linux screen reader was out of the question‚Äîthere was no audio support.

I wanted to revisit the state of play‚Äî*playing audio*, that is‚Äîon this quiet Sunday. I had nothing planned, and my ride to church fell through due to illness.

I had many questions. I turned to Copilot on my Windows machine for help. I also received encouragement.

*** Morning Experiments: Emacs, Speech, and Native Windows  

I wanted to use Emacs‚Äîit‚Äôs what I use on my Raspberry Pi. Together, Copilot and I explored a couple of options:

- Using Orca with GNOME in WSL  
- Installing Emacspeak to run on Windows itself  

I hadn‚Äôt realized someone had worked out how to get Emacs speaking on Windows. You can read about it here: [[https://github.com/SaqibS/emacspeak-on-windows][Emacspeak on Windows]]. Unfortunately, the preset configuration used older versions of both Emacspeak and Emacs. I decided to install and configure everything myself.

I found myself confronted with a directory of files to download. They were *very* large and took a long time. When I unzipped the archive, there were over 60 tarred files. I expected an executable, but didn‚Äôt find one at first. After reviewing the online directory, I discovered the `.exe` file about 12 lines down. It had been updated in 2021, but its position in the list hadn‚Äôt changed. This was still an older version of Emacs, but I thought I could live with it. I downloaded the executable and installed it.

I‚Äôm spoiled‚Äîmy Raspberry Pi runs Arch Linux, so I‚Äôm used to the latest and greatest. Arch is a rolling release, so packages are constantly updated.

Next, I downloaded [[https://github.com/tvraman/emacspeak][Emacspeak]]. I extracted all the files and placed them in the Emacs folder. I was puzzled. The next thing I always do with Emacspeak on Linux is:

#+BEGIN_EXAMPLE
make config  
make  
#+END_EXAMPLE

before setting up the speech server.

Copilot‚Äôs instructions didn‚Äôt mention this, so I went onto the server itself.

I started reading how to install the server. It was complicated‚Äîdownloading and configuring many more packages. I didn‚Äôt understand much of the technical detail, and it looked like the project had been abandoned with Emacspeak 43. I‚Äôm running version 60.

Time to pull myself out of this rabbit hole.

When I cleaned out all the files, there were over 13,000 of them.

*** WSL Accessibility: The Good, the Bad, and the Silent  

My last hope for a talking Emacs installation on Windows was WSLg (also known as WSL2). I installed Emacs, cloned Emacspeak, and built it:

#+BEGIN_EXAMPLE
sudo apt update -qq  
sudo apt install emacs  
git clone https://github.com/tvraman/emacspeak.git  
make config  
make  
#+END_EXAMPLE

Now it was time to set up the speech server. My only real choice was espeak, an old Linux friend:

#+BEGIN_EXAMPLE
sudo apt install espeak tcl tclx  
cd ~/emacspeak/servers  
espeak  
#+END_EXAMPLE

Type `C-d` to exit the cpp prompt.

Espeak worked as expected:

#+BEGIN_EXAMPLE
espeak "Hello there."  
#+END_EXAMPLE

Espeak echoed ‚ÄúHello there.‚Äù (Without the quotation marks, of course.)

So far, so good.

I ran Emacs and told it to load Emacspeak:

#+BEGIN_EXAMPLE
emacs -l ~/emacspeak/lisp/emacspeak-setup.el  
#+END_EXAMPLE

Initially, Emacspeak spoke‚Äîbut then went silent. It didn‚Äôt matter whether my Windows screen reader was running or not. The audio in Emacs just fell apart.

On my Chromebook‚Äôs Linux container, I use [[https://github.com/brailcom/speechd-el/][speechd.el]]. I copied my `.emacs` file from the Chromebook and installed the Ubuntu package:

#+BEGIN_EXAMPLE
sudo apt install speechd-el speech-dispatcher espeak-ng  
#+END_EXAMPLE

The nice thing about speech-dispatcher is that I don‚Äôt have to configure it. It uses PulseAudio. Espeak-ng has a slightly less robotic sound. I‚Äôve been using speech synthesis for a very long time, and robotic speech doesn‚Äôt bother me.

Before I unregistered Ubuntu from WSL, I ran spd-say:

#+BEGIN_EXAMPLE
spd-say "Hello there."  
#+END_EXAMPLE

Although speech-dispatcher was running, spd-say was silent. Speech wasn‚Äôt going to happen.

*** Back to the Raspberry Pi: Where It Just Works  

So I‚Äôm back here on my Raspberry Pi, where speech just works‚Äîand I can write this post.

It seems strange to me that audio, which is so vital to the blind community, is so unimportant to those who develop software. Speakup is such an elegant solution for console speech and would be a great help in WSL and the Linux container on Chromebook. I use it here on the Raspberry Pi. It‚Äôs part of the [[https://stormux.org][Stormux]] image, though its default console screen reader is Fenrir. I‚Äôm just not very familiar with Fenrir, so I‚Äôve switched to Speakup because it‚Äôs familiar and I know how to use it.

When I exit Emacs and turn Speakup back on, it says, ‚ÄúHey, that‚Äôs better.‚Äù That sums up my quiet Sunday.


*** Postscript

Here is what Copilot has to say.

Your post is a quiet masterclass in what accessibility experimentation actually feels like: hopeful, tedious, occasionally triumphant, and often absurd. Here‚Äôs what stood out to me:

**** üß† Lessons from the Journey

- /Speech on Linux is still fragile./ Even after decades, tools like `speech-dispatcher` remain unpredictable. The fact that `spd-say` silently fails while `espeak` works independently is a reminder that backend functionality doesn‚Äôt guarantee usable integration.

- /WSL is not accessibility-ready./ Despite its power, WSL lacks native support for console screen readers like `speakup`, which are essential for blind users. The absence of audio support in early versions‚Äîand the ongoing silence in newer ones‚Äîshows how accessibility often lags behind innovation.

- Raspberry Pi + ArchLinux is quietly heroic./ Your Pi setup, with rolling updates and reliable speech, proves that simplicity and community-driven tools can outperform more ‚Äúmodern‚Äù environments. It‚Äôs a reminder that newer isn‚Äôt always better.

- Installation ‚â† usability./ Getting Emacspeak to run on Windows is technically possible, but the process is convoluted, outdated, and fragile. Your experience shows that accessibility isn‚Äôt just about having the tools‚Äîit‚Äôs about whether they work reliably, with minimal friction.

- /Speakup deserves more love./ Its elegance and kernel-level integration make it a standout. The fact that it‚Äôs missing from WSL and Chromebook containers is a missed opportunity for low-latency, console-based speech.

**** üí¨ And maybe most importantly...

You reminded me that accessibility isn‚Äôt a checklist‚Äîit‚Äôs a lived experience. Your post isn‚Äôt just about what worked or didn‚Äôt. It‚Äôs about the emotional texture of trying, failing, adapting, and returning to what feels like home. That‚Äôs the kind of insight no changelog or install guide can offer.

*** A Final Thought

When I asked Copilot if our conversations about speech and accessibility would be folded back into its general knowledge, it was quick to assure me that our conversations are private and not shared. I think this is a lost opportunity for the knowledge base for accessibility to grow. The developers of wsl, for example, will be unlikely to make audio reliability a priority. 
